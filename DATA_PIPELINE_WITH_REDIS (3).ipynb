{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install redis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkZv1u6ub4nA",
        "outputId": "f53f23f9-831d-4e12-f195-302b4d7d8c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: redis in /usr/local/lib/python3.9/dist-packages (4.5.4)\n",
            "Requirement already satisfied: async-timeout>=4.0.2 in /usr/local/lib/python3.9/dist-packages (from redis) (4.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install psycopg2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no3ZnxWcsJ_s",
        "outputId": "ff6401a9-e96e-4b71-a36f-7f5004612fa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: psycopg2 in /usr/local/lib/python3.9/dist-packages (2.9.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import psycopg2\n",
        "import redis\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "id": "EGVfHNfLbYcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jH49d6d8aU7c"
      },
      "outputs": [],
      "source": [
        "\n",
        "r = redis.Redis(\n",
        "  host='redis-10441.c301.ap-south-1-1.ec2.cloud.redislabs.com',\n",
        "  port=10441,\n",
        "  password='QAfDAHOgHsGDaqZwFrXxyFqozH94Htj1')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a key-value pair in Redis \n",
        "r.set('key', 'value') \n",
        "\n",
        "# Retrieve the value from the key \n",
        "value = r.get('key') \n",
        "\n",
        "print(\"The value stored in Redis for key 'key' is: %s\" % value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Axulbk1Dj2zd",
        "outputId": "dfa5d469-b7e2-45af-8766-0d7772a73470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value stored in Redis for key 'key' is: b'value'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_data(filename):\n",
        "    # check if the data is cached in Redis\n",
        "    if r.exists('customer_call_logs'):\n",
        "        return pd.read_pickle(r.get('customer_call_logs'))\n",
        "    # extract data from CSV file\n",
        "    df = pd.read_csv(filename)\n",
        "    # cache data in Redis\n",
        "    with BytesIO() as f:\n",
        "        df.to_pickle(f)\n",
        "        r.set('customer_call_logs', f.getvalue())\n",
        "    return df"
      ],
      "metadata": {
        "id": "U0xsYjHalfHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_data(df):\n",
        "    # clean data\n",
        "    df = df.dropna()\n",
        "    # restructure data\n",
        "    df['call_duration'] = df['call_duration'].apply(lambda x: int(x.split(':')[0]) * 60 + int(x.split(':')[1]))\n",
        "    df['call_destination'] = df['call_destination'].apply(lambda x: '+1' + x.replace('-', ''))\n",
        "    # format data\n",
        "    df['call_date'] = pd.to_datetime(df['call_date'], format='%d-%m-%Y')\n",
        "    return df"
      ],
      "metadata": {
        "id": "kk8l62uHl6aH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipecho.net/plain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXkLfA6Xrpvj",
        "outputId": "fdaf1415-885e-4095-f2e8-b0de7f6a8fbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.185.116.123"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Postgres Database Information\n",
        "Postgres_host = '34.134.47.105'\n",
        "Postgres_database = 'Redis_db'\n",
        "Postgres_user = 'student3'\n",
        "Postgres_password = 'Test12'"
      ],
      "metadata": {
        "id": "nxWQoF4mdy1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(df, dbname, user, password, host):\n",
        "    # connect to database\n",
        "    conn = psycopg2.connect(dbname=Postgres_database, user=Postgres_user, password=Postgres_password, host=Postgres_host)\n",
        "    # create table\n",
        "    cur = conn.cursor()\n",
        "    cur.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS customer_call_logs\n",
        "        (\n",
        "            call_date DATE,\n",
        "            call_duration INTEGER,\n",
        "            call_destination VARCHAR(20),\n",
        "            call_cost FLOAT\n",
        "        );\n",
        "    ''')\n",
        "    conn.commit()\n",
        "    # load data into table\n",
        "    for row in df.itertuples(index=False):\n",
        "        cur.execute('''\n",
        "            INSERT INTO customer_call_logs (call_date, call_duration, call_destination, call_cost)\n",
        "            VALUES (%s, %s, %s, %s)\n",
        "        ''', row)\n",
        "    conn.commit()\n",
        "    cur.close()\n",
        "    conn.close()\n"
      ],
      "metadata": {
        "id": "TuOkYsUhl-jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_pipeline():\n",
        "  with open('customer_call_logs.csv', 'rb') as f:\n",
        "    filename = 'customer_call_logs.csv'\n",
        "    extracted_data = extract_data(BytesIO(f.read()))\n",
        "    transformed_data = transform_data(extracted_data)\n",
        "    load_data(transformed_data, Postgres_database, Postgres_user, Postgres_password, Postgres_host)\n",
        "    \n"
      ],
      "metadata": {
        "id": "sWxibYQkmqpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    data_pipeline()"
      ],
      "metadata": {
        "id": "azSxF_odsgEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Documentation for Redis-Python Pipeline**\n",
        "\n",
        "This document outlines the implementation of a Redis-Python pipeline for extracting, transforming, and loading (ETL) data into a PostgreSQL database. The pipeline is designed to read call logs from a CSV file, clean and format the data, cache it in Redis, and finally load it into a PostgreSQL database.\n",
        "\n",
        "**Best Practices**\n",
        "\n",
        "a) I recommend the use of Redis for caching to speed up the pipeline by reducing the time it takes to extract data from the CSV file and also ensure that data is available even when the pipeline is re-run.\n",
        "\n",
        "b) Its also  also good to use BytesIO for pickling.To cache data in Redis, the data is first pickled and then stored in Redis. The BytesIO module is used to store the pickled data in memory, which improves performance and reduces memory usage.\n",
        "\n",
        "c) Error handling through data transformation. The pipeline uses error handling to ensure that the data is clean and accurate. It checks for missing values, invalid data types, and ensures that data is in the correct format before loading it into PostgreSQL.\n",
        "\n",
        "d) Storing data in a database eg PostgreSQL is a good practice. PostgreSQL is used as the final data storage layer. It provides great data storage capabilities and ensures data integrity, reliability, and security.\n",
        "\n",
        "\n",
        "**Recommendations for Deployment**\n",
        "\n",
        "a) Use of Cloud-based Infrastructure to deploy the pipeline such as AWS or Google Cloud Platform is recommended. This provides scalability, flexibility, and cost-effectiveness.\n",
        "\n",
        "b) To secure sensitive information such as database credentials and API keys, a secrets management tool such as Vault or AWS Secrets Manager is recommended.\n",
        "\n",
        "d) To ensure the pipeline is running smoothly, logging and monitoring tools such as ELK Stack or Prometheus are recommended. These tools provide visibility into the pipeline and allow for easy debugging in case of errors.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "In conclusion, the Redis-Python pipeline is an efficient and effective way of extracting, transforming, and loading data into a PostgreSQL database. By following best practices and deploying the pipeline on a cloud-based infrastructure, the pipeline can be easily managed, scaled, and secured."
      ],
      "metadata": {
        "id": "fZW53mHDS0Oc"
      }
    }
  ]
}